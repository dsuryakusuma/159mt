{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm Project\n",
    "\n",
    "#### Music 159: Computer Programming for Music Applications\n",
    "#### Daniel Suryakusuma, UC Berkeley\n",
    "\n",
    "Prompt:\n",
    "\"The second part is an assignment, for a total of 65% of the grade (there is 5% in excess). Please choose one of two possible tracks. \n",
    "\n",
    "A: Compose an acusmatic piece (electronics only) using only the tools developed during this course: convolution in Python and heterodyne, cross-synthesis and spectral freeze in Max. Please provide a document that explains your compositional process. \n",
    "\n",
    "B: Create a new software for sound processing (in Python or Max) by combining the algorithms explained in the course: `convolution`, `deconvolution`, `heterodyning`, `cross-synthesis`, `spectral freeze`. Please provide a short document that explains your software and the source code.\"\n",
    "\n",
    "Let's build some music software in Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing existing code that we've already used earlier this semester. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conv_fast.py` as provided by Carmine-Emanuele Cella (slightly modified for our needs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_fast.py - fast convolution based reverberation\n",
      "saving data into file\n",
      "done saving!\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "# from os import path\n",
    "from pydub import AudioSegment\n",
    "import sys\n",
    "\n",
    "def next_power_of_2(x):\n",
    "    return 1 if x == 0 else 2 ** (x - 1).bit_length()\n",
    "\n",
    "def main():\n",
    "    print(\"conv_fast.py - fast convolution based reverberation\")\n",
    "#     x, srx = sf.read('anechoic1.wav') # 44.1 kHz sample rate (CD)\n",
    "#     h, srh = sf.read('Concertgebouw-m.wav') # 44.1 kHz sample rate (CD)\n",
    "    x, srx = sf.read('Beethoven_Symph7.wav')\n",
    "    h, srh = sf.read('Philips_mono.wav') # 44.1 kHz sample rate (CD)\n",
    "#     print (x.shape)\n",
    "#     print (h.shape)\n",
    "\n",
    "    if srx != srh: # sample rates\n",
    "        sys.exit('sr must be the same in both files')\n",
    "        \n",
    "    if x.shape[0] > h.shape[0]:\n",
    "        N = next_power_of_2(x.shape[0])\n",
    "    else:\n",
    "        N = next_power_of_2(h.shape[0])\n",
    "        \n",
    "    scale = 0.1\n",
    "    direct = 0.7\n",
    "    \n",
    "    y = np.fft.irfft ( np.fft.rfft (x,N) * np.fft.rfft (h,N) )\n",
    "    y *= scale\n",
    "    y[0:x.shape[0]] += x * direct\n",
    "    \n",
    "    print(\"saving data into file\")\n",
    "    sf.write(\"outverb.wav\", y, srx)\n",
    "    print(\"done saving!\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we're convolving a studio recording such as `anechoic1.wav` or `Diner.wav` with the sound signature (impulse response) at a concert hall `Concertgebouw-m.wav`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open('outverb.wav') # dont know how to open file inside here with python; might want terminal\n",
    "\n",
    "mt, srmt = sf.read('Diner.wav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider Wiener deconvolution. In the other direction, let's look at `deconv.py` as written by Carmine-Emanuele Cella (again modified for our needs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.py - convolution based reverberation\n",
      "(524288,)\n",
      "(225298,)\n",
      "deconvolving\n",
      "saving data\n",
      "done saving!\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def next_power_of_2(x):  \n",
    "    return 1 if x == 0 else 2**(x - 1).bit_length()\n",
    "\n",
    "def main():\n",
    "    print(\"conv.py - convolution based reverberation\")\n",
    "    y, syx = sf.read('outverb.wav')\n",
    "    x, srx = sf.read('Concertgebouw-m.wav')\n",
    "    # y, syx = sf.read('pedrotti_dump.wav')\n",
    "    # x, srx = sf.read('sweep.aif')\n",
    "    # x, srx = sf.read('Concertgebouw-m.wav')\n",
    "    print (x.shape)\n",
    "    # print (h.shape)    \n",
    "    print (y.shape)\n",
    "\n",
    "    scale = 3\n",
    "\n",
    "    N = next_power_of_2(y.shape[0])\n",
    "    ft_y = np.fft.fft (y, N)\n",
    "    ft_x = np.fft.fft (x, N)\n",
    "#     v =  max(abs(ft_x)) * 0.000005\n",
    "    v =  max(abs(ft_x)) * 0.005 # result is a lot better with this\n",
    "\n",
    "    print (\"deconvolving\")\n",
    "    # resynthesis\n",
    "    ir_rebuild = np.fft.irfft(ft_y * np.conj (ft_x) / (v + abs (ft_x) ** 2))\n",
    "\n",
    "    sig_len = y.shape[0] - x.shape[0]\n",
    "    ir_rebuild = ir_rebuild[1:sig_len] * scale\n",
    "\n",
    "    print (\"saving synthetic (impulse response) data\")\n",
    "    sf.write (\"ir_rebuild.wav\", ir_rebuild, srx)\n",
    "    print (\"done saving and writing!\")\n",
    "\n",
    "# main call\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deconvolution does appear to do the intended function; however, the resulting audio file is not what we expect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try convolving multiple times and see what we get. Code adapted from class materials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def next_power_of_2(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2 ** (x - 1) . bit_length()\n",
    "\n",
    "# def check_sample_rates(x_path, h_paths):\n",
    "#     x, x_sr = sf.read(x_path)\n",
    "#     h, h_sr = sf.read(h_path)\n",
    "#     return x_sr == h_sr\n",
    "\n",
    "def conv(x, h): \n",
    "    N = max( next_power_of_2(x.shape[0]) , next_power_of_2(h.shape[0]) ) # sample data points\n",
    "    \n",
    "    # customizable factors\n",
    "    scale = 0.1 # 0.1\n",
    "    direct = 0.7 # 0.7\n",
    "    \n",
    "    # perform fast convolution by multiplying the (fast) fourier transforms in frequency domain and inverting back\n",
    "    y = np.fft.irfft(  np.fft.rfft(x,N) * np.fft.rfft(h,N)  ) \n",
    "    y *= scale\n",
    "    y[ 0 : x.shape[0] ] += x * direct\n",
    "    \n",
    "    return(y) # returns the signal that would be written via sf.write(\"filename.wav\", y, x_sr)\n",
    "    \n",
    "    \n",
    "    \n",
    "def rep_conv(x_path, h_path, iters):\n",
    "    # x_path: .wav file for x signal\n",
    "    # h_path: .wav file for h system (impulse response) for convolution\n",
    "    # iters: integer number of iterations\n",
    "    \n",
    "    x, x_sr = sf.read(x_path)\n",
    "    h, h_sr = sf.read(h_path)\n",
    "    \n",
    "    if x_sr != h_sr:\n",
    "        sys.exit('sampling rate must be consistent between each input file')\n",
    "    \n",
    "    c = 0\n",
    "    while c < iters:\n",
    "        c += 1\n",
    "        x = conv(x, h)\n",
    "    \n",
    "    sf.write(\"test_outverb.wav\", x, x_sr)\n",
    "    print(\"output file created test_outverb.wav with\", iters, \"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file created test_outverb.wav with 3 iterations\n"
     ]
    }
   ],
   "source": [
    "rep_conv(\"Diner.wav\", \"Concertgebouw-m.wav\", 3) \n",
    "# yields unpleasant feedback at the tail of the signal for iters > 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try something different, adapted from [this article](https://stackoverflow.com/questions/43963982/python-change-pitch-of-wav-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1, 2, 44100, 960218, 'NONE', 'not compressed']\n",
      "[1, 2, 44100, 0, 'NONE', 'not compressed']\n",
      "_wave_params(nchannels=1, sampwidth=2, framerate=44100, nframes=0, comptype='NONE', compname='not compressed')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsury/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "import wave # seems to be more customizable over soundfile\n",
    "import dfply # for piping a la R's magrittr\n",
    "\n",
    "x_wave = wave.open(\"Diner.wav\", \"rb\") # option: read-only mode\n",
    "print(x_wave.getnchannels())\n",
    "\n",
    "x_params = list(x_wave.getparams())\n",
    "print(x_params) # parameters: nchannels, sampwidth, framerate, nframes, comptype, compname\n",
    "x_params[3] = 0 # set sampling rate to 0\n",
    "print(x_params) # sampling rate \n",
    "\n",
    "\n",
    "y_wave = wave.open(\"output_pitched.wav\", \"wb\") # option: write-only mode\n",
    "y_wave.setparams( x_params )\n",
    "\n",
    "print(y_wave.getparams())\n",
    "\n",
    "## partition x_wave\n",
    "frac = 100 # set this\n",
    "partition_size = x_wave.getframerate() // frac\n",
    "# int(c)\n",
    "\n",
    "shift = 100\n",
    "pitch_shift =  shift // frac\n",
    "\n",
    "for num in range(int( x_wave.getnframes() / partition_size )):\n",
    "    da = np.fromstring(x_wave.readframes(partition_size),\n",
    "                      dtype = np.int16)\n",
    "    left, right = da[0::2], da[1::2] # stereo audio\n",
    "\n",
    "    #fft for left and right frequencies:\n",
    "    left, right = np.fft.rfft(left), np.fft.rfft(right)\n",
    "    left, right = np.roll(left, pitch_shift), np.roll(right, pitch_shift) # roll the array to increase pitch \n",
    "    left[0:pitch_shift], right[0:pitch_shift] = 0, 0\n",
    "    \n",
    "    left, right = np.fft.irfft(left), np.fft.irfft(right) # convert back from frequency domain\n",
    "    \n",
    "    ns = np.column_stack( (left, right) ).ravel().astype(np.int16)\n",
    "    y_wave.writeframes(ns.tostring())\n",
    "\n",
    "    \n",
    "# for num in range(c):\n",
    "#     da = np.fromstring(x_wave.readframes(partition_size),\n",
    "#                       dtype = np.int16)\n",
    "#     #   left, right = da[0::2], da[1::2] # stereo audio\n",
    "\n",
    "#     #fft for left and right frequencies:\n",
    "#     fourier = np.fft.rfft(da)\n",
    "#     fourier = np.roll(fourier, pitch_shift) # roll the array to increase pitch \n",
    "    \n",
    "#     fourier[0:pitch_shift] = 0\n",
    "        \n",
    "#     ns = np.fft.irfft(fourier)\n",
    "    \n",
    "# #     ns = np.column_stack( (nl, nr) ).ravel().astype(np.int16) # combine both channels\n",
    "#     y_wave.writeframes(ns.tostring())\n",
    "\n",
    "    \n",
    "x_wave.close()\n",
    "y_wave.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import aubio\n",
    "\n",
    "aubio.float_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
