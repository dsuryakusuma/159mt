{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm Project\n",
    "\n",
    "#### Music 159: Computer Programming for Music Applications\n",
    "#### Daniel Suryakusuma, UC Berkeley\n",
    "\n",
    "Prompt:\n",
    "\"The second part is an assignment, for a total of 65% of the grade (there is 5% in excess). Please choose one of two possible tracks. \n",
    "\n",
    "A: Compose an acusmatic piece (electronics only) using only the tools developed during this course: convolution in Python and heterodyne, cross-synthesis and spectral freeze in Max. Please provide a document that explains your compositional process. \n",
    "\n",
    "B: Create a new software for sound processing (in Python or Max) by combining the algorithms explained in the course: `convolution`, `deconvolution`, `heterodyning`, `cross-synthesis`, `spectral freeze`. Please provide a short document that explains your software and the source code.\"\n",
    "\n",
    "Let's build some music software in Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing existing code that we've already used earlier this semester. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conv_fast.py` as provided by Carmine-Emanuele Cella (slightly modified for our needs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_fast.py - fast convolution based reverberation\n",
      "saving data into file\n",
      "done saving!\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "# from os import path\n",
    "from pydub import AudioSegment\n",
    "import sys\n",
    "\n",
    "def next_power_of_2(x):\n",
    "    return 1 if x == 0 else 2 ** (x - 1).bit_length()\n",
    "\n",
    "def main():\n",
    "    print(\"conv_fast.py - fast convolution based reverberation\")\n",
    "#     x, srx = sf.read('anechoic1.wav') # 44.1 kHz sample rate (CD)\n",
    "#     h, srh = sf.read('Concertgebouw-m.wav') # 44.1 kHz sample rate (CD)\n",
    "    x, srx = sf.read('Beethoven_Symph7.wav')\n",
    "    h, srh = sf.read('Philips_mono.wav') # 44.1 kHz sample rate (CD)\n",
    "#     print (x.shape)\n",
    "#     print (h.shape)\n",
    "\n",
    "    if srx != srh: # sample rates\n",
    "        sys.exit('sr must be the same in both files')\n",
    "        \n",
    "    if x.shape[0] > h.shape[0]:\n",
    "        N = next_power_of_2(x.shape[0])\n",
    "    else:\n",
    "        N = next_power_of_2(h.shape[0])\n",
    "        \n",
    "    scale = 0.1\n",
    "    direct = 0.7\n",
    "    \n",
    "    y = np.fft.irfft ( np.fft.rfft (x,N) * np.fft.rfft (h,N) )\n",
    "    y *= scale\n",
    "    y[0:x.shape[0]] += x * direct\n",
    "    \n",
    "    print(\"saving data into file\")\n",
    "    sf.write(\"outverb.wav\", y, srx)\n",
    "    print(\"done saving!\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we're convolving a studio recording such as `anechoic1.wav` or `Diner.wav` with the sound signature (impulse response) at a concert hall `Concertgebouw-m.wav`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open('outverb.wav') # dont know how to open file inside here with python; might want terminal\n",
    "\n",
    "mt, srmt = sf.read('Diner.wav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Wiener deconvolution. In the other direction, let's look at `deconv.py` as written by Carmine-Emanuele Cella (again modified for our needs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.py - convolution based reverberation\n",
      "(524288,)\n",
      "(225298,)\n",
      "deconvolving\n",
      "saving data\n",
      "done saving!\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def next_power_of_2(x):  \n",
    "    return 1 if x == 0 else 2**(x - 1).bit_length()\n",
    "\n",
    "def main():\n",
    "    print(\"conv.py - convolution based reverberation\")\n",
    "    y, syx = sf.read('outverb.wav')\n",
    "    x, srx = sf.read('Concertgebouw-m.wav')\n",
    "    # y, syx = sf.read('pedrotti_dump.wav')\n",
    "    # x, srx = sf.read('sweep.aif')\n",
    "    # x, srx = sf.read('Concertgebouw-m.wav')\n",
    "    print (x.shape)\n",
    "    # print (h.shape)    \n",
    "    print (y.shape)\n",
    "\n",
    "    scale = 3\n",
    "\n",
    "    N = next_power_of_2(y.shape[0])\n",
    "    ft_y = np.fft.fft (y, N)\n",
    "    ft_x = np.fft.fft (x, N)\n",
    "#     v =  max(abs(ft_x)) * 0.000005\n",
    "    v =  max(abs(ft_x)) * 0.005 # result is a lot better\n",
    "\n",
    "    print (\"deconvolving\")\n",
    "    # resynthesis\n",
    "    ir_rebuild = np.fft.irfft(ft_y * np.conj (ft_x) / (v + abs (ft_x) ** 2))\n",
    "\n",
    "    sig_len = y.shape[0] - x.shape[0]\n",
    "    ir_rebuild = ir_rebuild[1:sig_len] * scale\n",
    "\n",
    "    print (\"saving data\")\n",
    "    sf.write (\"ir_rebuild.wav\", ir_rebuild, srx)\n",
    "    print (\"done saving!\")\n",
    "\n",
    "# main call\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try convolving multiple times and see what we get. Code adapted from class materials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def next_power_of_2(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2 ** (x - 1) . bit_length()\n",
    "\n",
    "# def check_sample_rates(x_path, h_paths):\n",
    "#     x, x_sr = sf.read(x_path)\n",
    "#     h, h_sr = sf.read(h_path)\n",
    "#     return x_sr == h_sr\n",
    "\n",
    "def conv(x, h): \n",
    "    N = max( next_power_of_2(x.shape[0]) , next_power_of_2(h.shape[0]) ) # sample data points\n",
    "    \n",
    "    # customizable factors\n",
    "    scale = 0.1 # 0.1\n",
    "    direct = 0.7 # 0.7\n",
    "    \n",
    "    # perform fast convolution by multiplying the (fast) fourier transforms in frequency domain and inverting back\n",
    "    y = np.fft.irfft(  np.fft.rfft(x,N) * np.fft.rfft(h,N)  ) \n",
    "    y *= scale\n",
    "    y[ 0 : x.shape[0] ] += x * direct\n",
    "    \n",
    "    return(y) # returns the signal that would be written via sf.write(\"filename.wav\", y, x_sr)\n",
    "    \n",
    "    \n",
    "    \n",
    "def rep_conv(x_path, h_path, iters):\n",
    "    # x_path: .wav file for x signal\n",
    "    # h_path: .wav file for h system (impulse response) for convolution\n",
    "    # iters: integer number of iterations\n",
    "    \n",
    "    x, x_sr = sf.read(x_path)\n",
    "    h, h_sr = sf.read(h_path)\n",
    "    \n",
    "    if x_sr != h_sr:\n",
    "        sys.exit('sampling rate must be consistent between each input file')\n",
    "    \n",
    "    c = 0\n",
    "    while c < iters:\n",
    "        c += 1\n",
    "        x = conv(x, h)\n",
    "    \n",
    "    sf.write(\"test_outverb.wav\", x, x_sr)\n",
    "    print(\"output file created test_outverb.wav with\", iters, \"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file created test_outverb.wav with 3 iterations\n"
     ]
    }
   ],
   "source": [
    "rep_conv(\"Diner.wav\", \"Concertgebouw-m.wav\", 3) \n",
    "# yields unpleasant feedback at the tail of the signal for iters > 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try something different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wave # seems to be more customizable over soundfile\n",
    "\n",
    "x_wave = wave.open(\"Diner.wav\")\n",
    "x_wave.getnchannels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aubio\n",
    "\n",
    "aubio.float_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
